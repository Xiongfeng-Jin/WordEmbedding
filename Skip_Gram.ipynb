{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Skip-Gram.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Xiongfeng-Jin/WordEmbedding/blob/master/Skip_Gram.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x98Gcam1tZSv",
        "colab_type": "code",
        "outputId": "fb6099bf-bcec-440f-fda5-e7608f71e26f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "%matplotlib inline\n",
        "import collections\n",
        "import math\n",
        "import numpy as np\n",
        "import os\n",
        "import random\n",
        "import tensorflow as tf\n",
        "import bz2\n",
        "from matplotlib import pylab\n",
        "from six.moves import range\n",
        "from six.moves.urllib.request import urlretrieve\n",
        "from sklearn.manifold import TSNE\n",
        "from sklearn.cluster import KMeans\n",
        "import nltk # standard preprocessing\n",
        "import operator # sorting items in dictionary by value\n",
        "nltk.download('punkt') #tokenizers/punkt/PY3/english.pickle\n",
        "from math import ceil\n",
        "import csv"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mDa-9Q6cCyve",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tf.enable_eager_execution()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k6RGFIIKt17e",
        "colab_type": "text"
      },
      "source": [
        "Prepare Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IIaUzD_2ttB0",
        "colab_type": "code",
        "outputId": "57b9ac6d-4f07-49a7-8e58-5de892e6ad90",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "url = 'http://www.evanjones.ca/software/'\n",
        "\n",
        "def download_if_needed(filename,expected_bytes):\n",
        "  if not os.path.exists(filename):\n",
        "    print(\"Downloading file...\")\n",
        "    filename,_ = urlretrieve(url+filename,filename)\n",
        "  statinfo = os.stat(filename)\n",
        "  if statinfo.st_size == expected_bytes:\n",
        "    print(\"Found and verified %s\" % filename)\n",
        "  else:\n",
        "    print(statinfo.st_size)\n",
        "    raise Exception(\"Failed to verify\"+filename)\n",
        "  return filename\n",
        "\n",
        "filename = download_if_needed('wikipedia2text-extracted.txt.bz2', 18377035)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading file...\n",
            "Found and verified wikipedia2text-extracted.txt.bz2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yEIiQodwutYJ",
        "colab_type": "code",
        "outputId": "5bca1288-2dda-48ec-cad0-5a838d749a9d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "def read_data(filename):\n",
        "  with bz2.BZ2File(filename) as f:\n",
        "    data = []\n",
        "    file_string = f.read().decode('utf-8')\n",
        "    file_string = nltk.word_tokenize(file_string)\n",
        "    data.extend(file_string)\n",
        "  return data\n",
        "\n",
        "words = read_data(filename)\n",
        "print(\"data size %d\" % len(words))\n",
        "print(\"Example words: %s\" % words[:10])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "data size 11631723\n",
            "Example words: ['Propaganda', 'is', 'a', 'concerted', 'set', 'of', 'messages', 'aimed', 'at', 'influencing']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SXXbLgDWxBYN",
        "colab_type": "text"
      },
      "source": [
        "# Build word dictionary"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hha56p-xvTmg",
        "colab_type": "code",
        "outputId": "3857f0cd-08cf-4d6c-a482-6b8ebf84e993",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "vocabulary_size = 50000\n",
        "\n",
        "def build_dataset(words):\n",
        "  count = [['UNK',-1]]\n",
        "  count.extend(collections.Counter(words).most_common(vocabulary_size - 1))\n",
        "  dictionary = dict()\n",
        "  i = 0\n",
        "  for word,_ in count:\n",
        "    dictionary[word] = i\n",
        "    i += 1\n",
        "  \n",
        "  data = []\n",
        "  unk_count = 0\n",
        "  for word in words:\n",
        "    if word in dictionary:\n",
        "      index = dictionary[word]\n",
        "    else:\n",
        "      index = 0\n",
        "      unk_count += 1\n",
        "    data.append(index)\n",
        "    \n",
        "  count[0][1] = unk_count\n",
        "  reverse_dictionary = dict(zip(dictionary.values(),dictionary.keys()))\n",
        "  assert len(dictionary) == vocabulary_size\n",
        "  return data,count,dictionary,reverse_dictionary\n",
        "\n",
        "data,count,dictionary,reverse_dictionary = build_dataset(words)\n",
        "print(\"most common words\",count[:5])\n",
        "print(\"sample data\",data[:10])\n",
        "# del words"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "most common words [['UNK', 388121], ('the', 690296), (',', 632179), ('.', 439932), ('of', 402970)]\n",
            "sample data [18392, 9, 8, 19083, 221, 4, 6436, 3769, 30, 12058]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mhg8_Lka0fvJ",
        "colab_type": "text"
      },
      "source": [
        "## Generating Batches of Data for Skip-Gram"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gA7yYAQh0A-B",
        "colab_type": "code",
        "outputId": "680c3e78-7bec-4cd0-bfb2-b04026e663b9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "source": [
        "data_index = 0\n",
        "def generate_batch_skip_gram(batch_size,window_size):\n",
        "  global data_index\n",
        "  \n",
        "  batch = np.ndarray(shape=(batch_size),dtype=np.int32)\n",
        "  labels = np.ndarray(shape=(batch_size,1),dtype=np.int32)\n",
        "  \n",
        "  span = 2*window_size + 1\n",
        "  buffer = collections.deque(maxlen=span)\n",
        "  dataLen = len(data)\n",
        "  for _ in range(span):\n",
        "    buffer.append(data[data_index])\n",
        "    data_index = (data_index + 1) % dataLen\n",
        "    \n",
        "  num_samples = 2 * window_size\n",
        "  \n",
        "  for i in range(batch_size // num_samples):\n",
        "    k = 0\n",
        "    for j in list(range(window_size))+list(range(window_size+1,2*window_size+1)):\n",
        "      batch[i*num_samples + k] = buffer[window_size]\n",
        "      labels[i*num_samples + k,0] = buffer[j]\n",
        "      k += 1\n",
        "    buffer.append(data[data_index])\n",
        "    data_index = (data_index + 1) % dataLen\n",
        "\n",
        "  return batch,labels\n",
        "\n",
        "for window_size in [1,2]:\n",
        "  data_index = 0\n",
        "  batch,labels = generate_batch_skip_gram(batch_size=8,window_size=window_size)\n",
        "  print(\"window size:\",window_size)\n",
        "  print(\"batch:\",[reverse_dictionary[b] for b in batch])\n",
        "  print(\"labels:\",[reverse_dictionary[i] for i in labels.reshape(8)])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "window size: 1\n",
            "batch: ['is', 'is', 'a', 'a', 'concerted', 'concerted', 'set', 'set']\n",
            "labels: ['Propaganda', 'a', 'is', 'concerted', 'a', 'set', 'concerted', 'of']\n",
            "window size: 2\n",
            "batch: ['a', 'a', 'a', 'a', 'concerted', 'concerted', 'concerted', 'concerted']\n",
            "labels: ['Propaganda', 'is', 'concerted', 'set', 'is', 'a', 'set', 'of']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ILJVVcnU3_BD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "batch_size = 128\n",
        "embedding_size = 128\n",
        "window_size = 4\n",
        "valid_size = 16\n",
        "valid_window = 50\n",
        "valid_examples = np.array(random.sample(range(valid_window),valid_size))\n",
        "valid_examples = np.append(valid_examples,random.sample(range(1000,1000+valid_window),valid_size),axis=0)\n",
        "num_sampled = 32"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6kX-Flv6Bh4d",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "embeddings = tf.Variable(tf.random_uniform([vocabulary_size,embedding_size],-1.0,1.0))\n",
        "softmax_weights = tf.Variable(tf.truncated_normal([vocabulary_size,embedding_size],stddev=0.5/math.sqrt(embedding_size)))\n",
        "softmax_biases = tf.Variable(tf.random_uniform([vocabulary_size],0.0,0.01))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JAkavX_ZBnbs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def embed(train_dataset):\n",
        "  return tf.nn.embedding_lookup(embeddings,train_dataset)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GBJy-8MZDxMn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def loss(x,y):\n",
        "  return tf.nn.sampled_softmax_loss(\n",
        "      weights=softmax_weights,\n",
        "      biases=softmax_biases,\n",
        "      inputs=embed(x),\n",
        "      labels=y,\n",
        "      num_sampled=num_sampled,\n",
        "      num_classes=vocabulary_size\n",
        "  )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fBx8y0I2EgSk",
        "colab_type": "text"
      },
      "source": [
        "### Calculating word similarities"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GbHix3MAEWGn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_normalized_embeddings():\n",
        "  norm = tf.sqrt(tf.reduce_sum(tf.square(embeddings),1,keepdims=True))\n",
        "  normalized_embeddings = embeddings / norm\n",
        "  return normalized_embeddings\n",
        "\n",
        "def get_similarity():\n",
        "  valid_dataset = tf.constant(valid_examples, dtype=tf.int32)\n",
        "  normalized_embeddings = get_normalized_embeddings()\n",
        "  valid_embeddings = tf.nn.embedding_lookup(normalized_embeddings,valid_dataset)\n",
        "  similarity = tf.matmul(valid_embeddings,tf.transpose(normalized_embeddings))\n",
        "  return similarity"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SZhTqTxfFDTp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "optimizer = tf.train.AdagradOptimizer(1.0)\n",
        "def train(x,y):\n",
        "  optimizer.minimize(lambda:loss(x,y),var_list=[embeddings,softmax_weights,softmax_biases])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EbJJoVKgFckJ",
        "colab_type": "code",
        "outputId": "eaebbb64-100f-42f1-fb71-8a69d84bf2bb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 2907
        }
      },
      "source": [
        "num_steps = 100001\n",
        "skip_losses = []\n",
        "average_loss = 0\n",
        "for step in range(num_steps):\n",
        "  batch_data,batch_labels = generate_batch_skip_gram(batch_size,window_size)\n",
        "  batch_data = tf.constant(batch_data,dtype=tf.int32)\n",
        "  batch_labels = tf.constant(batch_labels,dtype=tf.int32)\n",
        "  train(batch_data,batch_labels)\n",
        "  if (step+1) % 10000 == 0:\n",
        "    sim = get_similarity()\n",
        "    for i in range(valid_size):\n",
        "      valid_word = reverse_dictionary[valid_examples[i]]\n",
        "      top_k = 8\n",
        "      nearest = (-sim[i,:]).numpy().argsort()[1:top_k+1]\n",
        "      log = \"Nearest to %s: \" % valid_word\n",
        "      for k in range(top_k):\n",
        "        close_word = reverse_dictionary[nearest[k]]\n",
        "        log = \"%s %s,\" % (log,close_word)\n",
        "      print(log)\n",
        "    print(\"-\"*100)\n",
        "      \n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Nearest to on:  the, ., ,, of, The, a, and, is,\n",
            "Nearest to are:  to, ,, ., of, the, as, in, UNK,\n",
            "Nearest to is:  ., and, ,, the, of, to, in, a,\n",
            "Nearest to also:  is, of, '', ., ,, to, which, for,\n",
            "Nearest to which:  in, was, ,, to, ., the, of, is,\n",
            "Nearest to the:  of, ., ,, in, and, a, to, was,\n",
            "Nearest to has:  for, ., of, the, is, in, on, (,\n",
            "Nearest to of:  the, ,, ., and, in, to, a, is,\n",
            "Nearest to (:  ., ,, the, of, to, a, The, in,\n",
            "Nearest to have:  in, ., a, to, the, with, that, ,,\n",
            "Nearest to his:  in, ., of, ,, '', as, and, the,\n",
            "Nearest to by:  ,, in, the, of, a, ., and, to,\n",
            "Nearest to or:  and, of, to, is, (, in, the, UNK,\n",
            "Nearest to that:  ., the, and, of, to, ,, is, a,\n",
            "Nearest to to:  of, ,, ., the, in, as, and, a,\n",
            "Nearest to first:  ,, and, ., of, in, the, is, for,\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Nearest to on:  the, in, of, a, UNK, ., and, to,\n",
            "Nearest to are:  the, by, ,, UNK, of, and, ., to,\n",
            "Nearest to is:  the, to, ., of, in, and, ,, UNK,\n",
            "Nearest to also:  a, for, the, of, '', in, UNK, ``,\n",
            "Nearest to which:  UNK, ,, the, a, in, ., and, of,\n",
            "Nearest to the:  of, ., UNK, ,, to, in, and, a,\n",
            "Nearest to has:  a, of, in, and, was, to, ., the,\n",
            "Nearest to of:  the, in, ., a, ,, to, and, UNK,\n",
            "Nearest to (:  ), UNK, ., ,, in, and, to, the,\n",
            "Nearest to have:  a, by, of, ., in, ,, and, an,\n",
            "Nearest to his:  in, ., of, a, 's, and, the, to,\n",
            "Nearest to by:  ,, the, UNK, ., of, to, and, in,\n",
            "Nearest to or:  the, ., to, is, and, ,, UNK, a,\n",
            "Nearest to that:  to, of, the, ., ,, in, a, and,\n",
            "Nearest to to:  ., the, and, ,, of, in, a, UNK,\n",
            "Nearest to first:  to, ., from, UNK, the, a, ,, at,\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Nearest to on:  ,, ., and, of, to, in, 's, a,\n",
            "Nearest to are:  's, ,, and, ., in, to, of, the,\n",
            "Nearest to is:  ,, and, ., of, The, in, the, was,\n",
            "Nearest to also:  ,, ., is, was, to, of, the, from,\n",
            "Nearest to which:  ,, of, to, the, and, ., a, in,\n",
            "Nearest to the:  of, ., ,, and, in, to, was, 's,\n",
            "Nearest to has:  of, ., the, ,, and, in, a, to,\n",
            "Nearest to of:  ., the, ,, and, in, to, a, was,\n",
            "Nearest to (:  ), and, ,, of, UNK, a, in, is,\n",
            "Nearest to have:  and, ., ,, as, to, of, a, in,\n",
            "Nearest to his:  of, ,, the, ., by, in, and, a,\n",
            "Nearest to by:  ,, ., of, and, the, a, was, in,\n",
            "Nearest to or:  ., in, were, the, ,, and, of, a,\n",
            "Nearest to that:  and, of, the, ., a, to, ,, in,\n",
            "Nearest to to:  ., and, of, ,, the, in, a, was,\n",
            "Nearest to first:  of, ,, and, is, as, in, ., the,\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Nearest to on:  ., ,, to, in, the, a, of, is,\n",
            "Nearest to are:  which, the, ., of, ,, to, in, as,\n",
            "Nearest to is:  ,, of, in, ., the, to, for, a,\n",
            "Nearest to also:  with, which, in, of, is, the, ., as,\n",
            "Nearest to which:  in, the, ), to, as, ., are, of,\n",
            "Nearest to the:  of, in, ., ,, to, and, UNK, a,\n",
            "Nearest to has:  is, of, the, to, in, ,, for, .,\n",
            "Nearest to of:  the, ., ,, a, to, UNK, in, and,\n",
            "Nearest to (:  ), of, ,, in, for, the, from, and,\n",
            "Nearest to have:  with, to, for, is, be, of, other, and,\n",
            "Nearest to his:  to, with, UNK, and, is, of, ,, an,\n",
            "Nearest to by:  of, the, ,, ., a, in, UNK, and,\n",
            "Nearest to or:  ,, for, of, to, a, ., is, UNK,\n",
            "Nearest to that:  of, ., the, a, ,, and, in, to,\n",
            "Nearest to to:  ., ,, of, the, a, in, UNK, and,\n",
            "Nearest to first:  was, ,, the, by, of, in, to, and,\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Nearest to on:  ., the, and, of, UNK, a, in, ,,\n",
            "Nearest to are:  the, ,, and, UNK, of, by, ., to,\n",
            "Nearest to is:  the, ., of, to, in, UNK, a, ,,\n",
            "Nearest to also:  ., the, in, ,, of, with, and, has,\n",
            "Nearest to which:  and, the, ,, a, UNK, of, to, .,\n",
            "Nearest to the:  of, in, and, ., UNK, ,, to, is,\n",
            "Nearest to has:  ., and, the, ,, UNK, to, been, on,\n",
            "Nearest to of:  the, UNK, and, ., ,, in, a, is,\n",
            "Nearest to (:  UNK, the, to, ), in, a, '', .,\n",
            "Nearest to have:  (, the, ., been, UNK, and, ,, for,\n",
            "Nearest to his:  the, for, UNK, a, and, ., of, in,\n",
            "Nearest to by:  the, and, ., ,, UNK, ), to, in,\n",
            "Nearest to or:  the, ., of, UNK, and, ,, in, to,\n",
            "Nearest to that:  to, the, a, is, UNK, in, ., ,,\n",
            "Nearest to to:  the, UNK, ., ,, and, a, in, of,\n",
            "Nearest to first:  the, at, UNK, (, a, was, in, 's,\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Nearest to on:  ,, ., the, to, and, of, a, that,\n",
            "Nearest to are:  and, to, ,, of, the, in, which, by,\n",
            "Nearest to is:  that, ,, and, of, the, UNK, a, to,\n",
            "Nearest to also:  with, in, UNK, ,, The, of, a, .,\n",
            "Nearest to which:  ,, a, the, of, and, to, ., UNK,\n",
            "Nearest to the:  of, ,, and, ., to, a, UNK, in,\n",
            "Nearest to has:  of, the, a, in, ., and, ,, UNK,\n",
            "Nearest to of:  the, and, ,, ., a, UNK, to, in,\n",
            "Nearest to (:  ), in, ,, ., as, and, UNK, the,\n",
            "Nearest to have:  and, to, ,, of, ., a, for, the,\n",
            "Nearest to his:  to, ,, and, UNK, a, an, is, of,\n",
            "Nearest to by:  and, ,, in, the, to, UNK, which, of,\n",
            "Nearest to or:  the, and, of, UNK, to, ,, is, in,\n",
            "Nearest to that:  the, ,, of, is, as, ., in, and,\n",
            "Nearest to to:  ,, and, the, ., UNK, a, of, in,\n",
            "Nearest to first:  ,, ., a, the, on, UNK, from, with,\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Nearest to on:  the, a, and, ,, was, in, ., of,\n",
            "Nearest to are:  and, as, ,, is, which, the, in, .,\n",
            "Nearest to is:  of, ., the, a, in, and, ,, UNK,\n",
            "Nearest to also:  the, that, in, a, of, ., ,, as,\n",
            "Nearest to which:  and, ,, is, the, in, ., a, of,\n",
            "Nearest to the:  ., of, ,, a, and, in, was, UNK,\n",
            "Nearest to has:  the, and, ., in, a, of, ,, to,\n",
            "Nearest to of:  the, ., a, ,, and, is, in, UNK,\n",
            "Nearest to (:  ), ., the, and, of, a, UNK, ,,\n",
            "Nearest to have:  ., the, a, ,, was, as, in, of,\n",
            "Nearest to his:  's, was, by, the, ., ,, a, in,\n",
            "Nearest to by:  the, was, a, ,, and, of, ., as,\n",
            "Nearest to or:  UNK, ., a, ,, of, the, and, (,\n",
            "Nearest to that:  the, a, to, ., of, was, and, as,\n",
            "Nearest to to:  and, the, ., ,, a, of, is, in,\n",
            "Nearest to first:  's, was, in, a, have, The, ., the,\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Nearest to on:  as, a, to, 's, the, that, of, .,\n",
            "Nearest to are:  the, and, a, ,, two, ., as, to,\n",
            "Nearest to is:  a, the, The, ., ,, and, by, of,\n",
            "Nearest to also:  the, of, a, ,, and, ., The, that,\n",
            "Nearest to which:  and, a, to, the, was, ,, is, .,\n",
            "Nearest to the:  of, ., ,, and, a, in, to, The,\n",
            "Nearest to has:  as, a, ., The, been, of, to, ,,\n",
            "Nearest to of:  the, ., a, ,, and, in, The, that,\n",
            "Nearest to (:  ), UNK, ,, and, ., to, a, the,\n",
            "Nearest to have:  a, and, ., as, with, that, to, its,\n",
            "Nearest to his:  ., of, a, and, the, ,, that, to,\n",
            "Nearest to by:  ., ,, is, and, in, a, The, the,\n",
            "Nearest to or:  a, ,, the, to, and, of, ., from,\n",
            "Nearest to that:  a, the, and, ., of, to, ,, as,\n",
            "Nearest to to:  a, ,, the, ., and, of, as, The,\n",
            "Nearest to first:  a, ,, ., in, the, of, and, that,\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Nearest to on:  ., ,, the, and, of, to, The, UNK,\n",
            "Nearest to are:  UNK, that, ), from, to, be, The, and,\n",
            "Nearest to is:  The, to, from, as, of, UNK, and, a,\n",
            "Nearest to also:  that, a, ,, of, on, to, The, the,\n",
            "Nearest to which:  of, ., in, ,, the, and, a, as,\n",
            "Nearest to the:  ., of, ,, and, in, a, to, UNK,\n",
            "Nearest to has:  and, that, (, was, ), from, is, UNK,\n",
            "Nearest to of:  the, ., ,, and, a, in, The, to,\n",
            "Nearest to (:  ), UNK, ,, The, and, ., of, from,\n",
            "Nearest to have:  to, The, a, ., from, and, of, '',\n",
            "Nearest to his:  he, ), from, (, that, a, '', by,\n",
            "Nearest to by:  a, the, of, ., ,, and, to, in,\n",
            "Nearest to or:  The, is, of, and, ., to, a, an,\n",
            "Nearest to that:  ,, of, ., to, the, was, in, from,\n",
            "Nearest to to:  of, ., a, and, ,, the, The, in,\n",
            "Nearest to first:  in, ,, ., of, the, was, and, UNK,\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Nearest to on:  a, to, of, ., in, ,, and, the,\n",
            "Nearest to are:  and, not, that, to, with, a, in, .,\n",
            "Nearest to is:  of, the, ,, in, ., and, a, UNK,\n",
            "Nearest to also:  a, ., ,, by, was, and, that, to,\n",
            "Nearest to which:  the, and, ,, ., in, of, is, a,\n",
            "Nearest to the:  of, ., ,, in, and, to, a, was,\n",
            "Nearest to has:  and, ., ,, in, a, be, with, was,\n",
            "Nearest to of:  the, ., ,, and, in, to, a, was,\n",
            "Nearest to (:  ), ,, ., in, UNK, and, the, of,\n",
            "Nearest to have:  to, ,, as, by, and, ., a, in,\n",
            "Nearest to his:  with, a, by, to, ,, and, ., that,\n",
            "Nearest to by:  was, to, and, ., a, ,, of, the,\n",
            "Nearest to or:  and, a, to, ,, of, ., not, the,\n",
            "Nearest to that:  a, and, to, not, with, for, was, by,\n",
            "Nearest to to:  ., and, a, ,, of, in, the, was,\n",
            "Nearest to first:  was, in, ,, ., and, a, of, with,\n",
            "----------------------------------------------------------------------------------------------------\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}